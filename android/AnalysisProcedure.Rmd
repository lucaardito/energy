---
title: "Analysis Procedure"
author: "Marco Torchiano"
date: "19 November 2015"
output: html_document
---
```{r setup,echo=FALSE}
library(ggplot2)
library(plyr)
library(reshape2)
library(knitr)
source("Utility.R")
```

Computes the average power for the working tasks in a series of measures.

The computation assumes the execution follows a well defined protocol
to mark tasks begin and end. A typical profile is:

           --------      --v-^v^--
           |      |      |       |
           |      |      |       |
     -------      --------       -....
      SLEEP: WAIT :SLEEP : WORK  :   

`SLEEP` : is a period of sleep for a given (marker.length) time

`WAIT`  : is a period of busy waiting for a given (marker.length) time

`WORK` : is a period of actual work 
         (the one we aim to measure the energy consumption of)


Load data
---------

The analysis procedure can be applied on data containing Power samples.

Typically file containing current (`I`) values (expressed in Ampere) is the
starting point.

The power, given a _constant_ `voltage` in output from the
generator (`r voltage` V) -- can be computer using the basic relation 

$$P=V \cdot I$$

```{r load data}
  filepath = "data/syscall_mmap2.txt"
  #filepath = "data/syscall_futex.txt"
  #filepath = "data/syscall_gettimeofday.txt"
  #filepath = "data/syscall_mprotect.txt"
  voltage = 5.03 ## Volt

  # read the file containing current values (in A)
  data = read.delim2(filepath, header = FALSE, skip = 7)
  names(data)="I"

#  data = read.csv("~/Dropbox/PhDRifat/ENERGY ESEM 2015/Samples/Java/JavaBubble10000.csv")
#  names(data)[2]="I"
#  marker.length=1000

  # compute the power
  data$P <- with(data, I*voltage )
```



Input parameters
----------------

The algorithm takes the following input parameters:

```{r parameters}
adjust = 1.5 ## density parameter
marker.length = 5000
marker.tolerance= 0.1
N = 30 # number of task markers
```


Density analysis
----------------

Compute the distribution density of the instant power
in order to identify the typical working levels.

```{r compute distribution density}
  ## Distribution density of values
  dens <- density(data$P,adjust=adjust)
  #dens <- density(data$P)
  
  ## Find peaks in the distribution (the most common power levels)
  dens$peaks <- which(peaks(dens$y) & dens$y>mean(dens$y))
  
  ## Identify thresholds between peaks as the points of minimum density between peaks
  thresholds = dens$x[apply(cbind(head(dens$peaks,-1),tail(dens$peaks,-1)),1,function(x){
    ss = dens$y[x[1]:x[2]]
    x[1] + which(ss == min(ss))
  })]

  baseline = dens$x[dens$peaks[1]]
```

```{r plot density, echo=FALSE}
  p=ggplot(as.data.frame(dens[c("x","y")]),aes(x=x,y=y))+geom_line()
  p <- p+xlab("Power [W]")+ylab("Density")
  p <- p+geom_point(data=with(dens,data.frame(x=x[peaks],y=y[peaks])),size=4,pch=1,col="red")
  p <- p+annotate("segment",x=min(dens$x),xend=max(dens$y),y=mean(dens$y),yend=mean(dens$y),col="blue",lty=2)
  p <- p+annotate("segment",x=thresholds,xend=thresholds,y=0,yend=max(dens$y),col="red")
  
  p
```

The baseline, representing the idle level of consumption correspond to the first 
peak in the density plot: `r baseline` W.

Tagging
-------

Each peak is assigned to a level, the the thresholds are used to discriminate between consecutive levels. The data points are tagged with the level name.

The tagging indetify runs of consecutive points having the same level. The runs are then identified with a unique number.

To avoid manipulating the whole series of points, a summary table is computed that reports:

- tag
- run ID
- length
- start position
- end position

```{r tagging}
  ## tag levels are those corresponding to peaks plus a special NOISE tag
  tag.levels <- paste0("L",seq(dens$peaks))
  data$tag <- factor(tag.levels[findInterval(data$P,c(0,thresholds))],c(tag.levels,"NOISE"))

  ## assign unique id to runs
  data$runid <- cumsum(c(1,abs(diff(as.numeric(data$tag))!=0) ) )
  
  ## build run summary table
  id.tab = subset(melt(with(data,table(tag,runid)),id.vars="runid",value.name="length"),length!=0)
  id.tab$start=cumsum(c(1,head(id.tab$length,-1)))
  id.tab$end=cumsum(id.tab$length)
```

```{r plot tagged data, echo=FALSE}
  p <- ggplot(head(data,50000),aes(y=P,x=seq_along(P),color=tag))+geom_point(size=1,alpha=.5)
  p

  p <- ggplot(head(id.tab,1000),aes(x=start,y=tag,color=tag))
  p <- p+geom_segment(aes(xend=end,yend=tag))
  p <- p+geom_rect(aes(xmin=start,xmax=end,ymin=as.numeric(tag)-0.5,ymax=as.numeric(tag)+0.5,
                       fill=tag),alpha=0.2,color=NA)
  p
```

Denoise
-------

The collected measures are subject to noise (as any measure is).
Generally there are series of a few points that have a different value.

```{r characterize noise}
  dens = density(id.tab$length)
  dens$peaks <- which(peaks(dens$y) & dens$y>mean(dens$y))
  
  ## Identify thresholds between peaks as the points of minimum density between peaks
  thresholds = dens$x[apply(cbind(head(dens$peaks,-1),tail(dens$peaks,-1)),1,function(x){
    ss = dens$y[x[1]:x[2]]
    x[1] + which(ss == min(ss))
  })]
  noise=thresholds[1]
```

```{r plot noise density,echo=FALSE,warning=FALSE}
  p=ggplot(as.data.frame(dens[c("x","y")]),aes(x=x,y=y))+geom_line()
  p <- p+xlab("Power [W]")+ylab("Density")
  p <- p+geom_point(data=with(dens,data.frame(x=x[peaks],y=y[peaks])),size=4,pch=1,col="red")
  p <- p+annotate("segment",x=min(dens$x),xend=max(dens$y),y=mean(dens$y),yend=mean(dens$y),col="blue",lty=2)
#  p <- p+annotate("segment",x=thresholds,xend=thresholds,y=0,yend=max(dens$y),col="red")
  p <- p+geom_segment(data=data.frame(x=thresholds),
                      aes(xend=x,y=0,yend=max(dens$y)),col="red",linetype=2)
  p <- p + scale_x_log10()
  p

```


A possible suggested threshold for noise is: `r thresholds[1]`

In most cases the nois is a small variation around the expected value.
Though, in some cases the noise is so large to cause a different tag to be assigned.

We have, first, to identify the noise using a `noise` threshold on the lenght of the runs.

```{r identify noise}
  ## identify noise runs by means of a run length threshold
  id.tab$tag[id.tab$length<noise] = "NOISE"
```

```{r plot runs with noise,echo=FALSE}
  p <- ggplot(head(id.tab,1000),aes(x=start,y=tag,color=tag))
  p <- p+geom_segment(aes(xend=end,yend=tag))
  p <- p+geom_rect(aes(xmin=start,xmax=end,ymin=as.numeric(tag)-0.5,ymax=as.numeric(tag)+0.5,fill=tag),alpha=0.2,color=NA)
  p
```

Then, we can remove the noise using some strategy:

- merge noise run with the preceding run
- merge the noise run with either the preceding or the following one, depending which is the largest.

```{r remove noise}

  ## Remove noise
  if(id.tab$tag[1]=="NOISE"){
    id.tab$tag[1] = id.tab$tag[min(id.tab$runid[id.tab$tag!="NOISE"])]
  }
  id.noise = which(id.tab$tag=="NOISE")
  while(length(id.noise)>0){
    ##  assign the noise run the same level as the  the preceding run
    id.tab$tag[id.noise] = id.tab$tag[id.noise-1]
    id.noise = which(id.tab$tag=="NOISE")
  }
  ## id.tab = id.tab[order(id.tab$runid),] ### probably not useful
  
  ## Merge consecutive runs havin the same tag
  ## a) recompute the run id
  id.tab$runid = cumsum(c(1,abs(diff(as.numeric(id.tab$tag))!=0) ) )
  ## b) merge all the fragments with the same runid
  id.tab = ddply(id.tab,.(runid,tag),summarize,
                 length = sum(length),
                 start = min(start),
                 end = max(end)
                 )
```

```{r plot denoised,echo=FALSE}
  data$tag = rep(id.tab$tag,id.tab$length)
  p <- ggplot(head(data,50000),aes(y=P,x=seq_along(P),color=tag))+geom_point(size=1,alpha=.5)
  p

  p <- ggplot(id.tab,aes(x=start,y=tag,color=tag))
  p <- p+geom_segment(aes(xend=end,yend=tag))
  p <- p+geom_rect(aes(xmin=start,xmax=end,ymin=as.numeric(tag)-0.5,ymax=as.numeric(tag)+0.5,fill=tag),alpha=0.2,color=NA)
  p

  kable(head(id.tab,10))
```

Identify task markers
---------------------

Then we need to identify the marker that introduce the experiment.

We do not make any hypothesis as to the level at which markers are found (it should be the highest one...)

The markers are (a subset of) the runs whose lenght is close to the predefined marker length.

First we need to understand at which level (tag) are located the markers.
   
  For each distinct level/run:
  
  - Count how many runs are in the expected range 
    (the interval centered around `marker.length` with emiwidth `marker.tolerance`).
    
  - Compute the median period separating two consecutive runs

  - Compute the standard deviation of the period separating two consecutive runs
  
  - Select as marker level/tag the one 
     with the number of potential markers, closer to
     the expected value (`N`) and with the smallest variability
     around of the period.

```{r identify markers levels}
  l.min = marker.length*(1-marker.tolerance)
  l.max = marker.length*(1+marker.tolerance)
  markers = subset(id.tab,length>=l.min & length<=l.max)
  mark.sum = ddply(markers,.(tag),summarize,
        n=length(tag),
        length = median(length),
        t= median(diff(start)),
#        tv = sd(diff(start))
#        tv = 2*diff(quantile(diff(start),c(.25,.75)))
        tv = median(diff(start))*.1
        )
  mark.sum$score = dim(mark.sum)[1]*(rank(abs(mark.sum$n-N))-1)+rank(mark.sum$tv)-1
  marker = subset(mark.sum,score==min(score))
  marker.tag = marker$tag

  kable(mark.sum)
```

- the initial set of markers are the runs in the expected range

- the we proceed with all the markers trying to find the next one
  either in the existing set of markers or in the runs with the market tag


```{r identify markers}
  potential.markers = subset(id.tab,tag==marker$tag)

  selected.markers = c()
  initial.markers = subset(markers,tag==marker$tag)
  print(initial.markers$runid)
  generation = 0
  while(!is.null(initial.markers)){
    generation <- generation + 1
    if(generation > 5) break
    new.markers=c()
    for(id in initial.markers$runid){
      #cat(id,"\n")
      current.marker = subset(potential.markers,runid==id)
      t.expected = current.marker$start + marker$t
      t.lower = t.expected - marker$tv
      t.upper = t.expected + marker$tv
      
      successor = subset(potential.markers,start>=t.lower & start<=t.upper & length>marker.length/2)
      if(dim(successor)[1]>0){
        if(dim(successor)[1]>1){
          successor <- subset(successor,abs(length-marker.length)==min(abs(length-marker.length)))
          #stop("No strategy to prioritize defined yet!!")
        }
        if(! successor$runid%in%selected.markers$runid){
          new.markers <- rbind(new.markers,successor)
        }
      }
      
      t.expected = current.marker$start - marker$t
      t.lower = t.expected - marker$tv
      t.upper = t.expected + marker$tv
      predecessor = subset(potential.markers,start>=t.lower & start<=t.upper& length>marker.length/2)
      if(dim(predecessor)[1]>0){
        if(dim(predecessor)[1]>1){
          predecessor <- subset(predecessor,abs(length-marker.length)==min(abs(length-marker.length)))
        }
        if(! predecessor$runid%in%selected.markers$runid){
          new.markers <- rbind(new.markers,predecessor)
        }
      }
    }
    new.markers = unique(new.markers)
    initial.markers=new.markers
    if(!is.null(new.markers)){
      print(new.markers$runid)

      new.markers$Gen = generation
      selected.markers=rbind(selected.markers,new.markers)
    }
  }
  selected.markers <- unique(selected.markers)
  selected.markers <- selected.markers[order(selected.markers$runid),]
```

```{r plot runs with markers,echo=FALSE, fig.width=14,fig.height=6}
  selected.markers$Gen = factor(selected.markers$Gen)

  p <- ggplot(id.tab,aes(x=start,y=tag,color=tag))
  p <- p+geom_segment(aes(xend=end,yend=tag))
  p <- p+geom_rect(data=selected.markers,aes(xmin=start,xmax=end,ymin=0.5,ymax=as.numeric(tag)+0.5,fill=Gen),alpha=0.2,color=NA)
  p
```

The procedure identified `r dim(selected.markers)[1]` markers.
The average length of markers is `r mean(selected.markers$length)`, median: `r median(selected.markers$length)`, sd: `r sd(selected.markers$length)`.


`r kable(selected.markers)`

Identify work
-------------

For each marker, identify the beginning and end of the work run.

Possible options:

1. **End + T _to_ Start - T** (E2S): 
  Skip a `marker.length` after marker _end_: that's the beginning of a work; 
  stop `marker.length` before the next marker _start_ 
```{r identify work E2S}
work = data.frame(
      start = head(selected.markers,-1)$end+marker.length,
      end = tail(selected.markers,-1)$start-marker.length
      )
work <- within(work,
       length <- end-start
       )
summary(work)
```

2. **Start + 2 T _to_ Start - T** (S2S):
  Skip two `marker.length`s after marker _end_: that's the beginning of a work; 
  stop `marker.length` before the next marker _start_ 
```{r identify work S2S}
work.run = data.frame(
      start = head(selected.markers,-1)$start+2*marker.length,
      end = tail(selected.markers,-1)$start-marker.length
      )
work.run <- within(work.run,
       length <- end-start+1
       )
summary(work.run)
```

The second approach consistently gives better and more consistent results.

```{r plot work runs with markers,echo=FALSE, fig.width=14,fig.height=6}
  p <- ggplot(id.tab,aes(x=start,y=tag,color=tag))
  p <- p+geom_segment(aes(xend=end,yend=tag))
  p <- p+geom_rect(data=work.run,aes(xmin=start,xmax=end,ymin=0.5,ymax=3.5,color=NA,y=NA),alpha=0.2,color=NA)
  p
```

Extract work data
---------------------

```{r extract work data}

work.run$P <- apply(work.run,1,function(x) 
                      mean(data[x["start"]:x["end"],]$P)-baseline)

```

```{r plot work mean power}
p <- ggplot(data=work.run,aes(x='',y=P))+geom_boxplot()
p <- p+geom_segment(aes(yend=P),x=0.5,xend=0.52)
p
```



